"""
Find messages which appear to be duplicates in the messages data.
Uses USE to generate embeddings for each message, and compares
them with cosine similarity.

After it computes embeddings, it saves them to the SCRATCH_DIR folder.

I ENDED UP ONLY USING THIS SCRIPT FOR EMBEDDINGS!
THE ACTUAL THING I USED TO COMPUTE SIMILARITY IS IN compute_cosine_similarity.py!
It turned out computing cosine similarity between n^2 USE embeddings
was very slow for the hundreds of thousands of messages in the dataset,
so instead of computing cosine similarity for all pairs of messages
from the start, I decided to chunk this computation into smaller batches
that could run in hours instead of days. Since I already had the embeddings
generated by this script, I used them in compute_cosine_similarity.py, and
combined each similarity family file into one big one using
collapse_similarity_families.py.
"""

import csv
import pickle
import os
import os.path
from sklearn.metrics.pairwise import cosine_similarity
import tensorflow_hub as hub

MESSAGES = list(csv.reader(open("messages_all.txt.alphaonly.csv", "r")))
SCRATCH_DIR = "./scratch"

deemed_similar = set() # message numbers of all messages already deemed similar to another message
similarity_families = {} # sets of messages similar to a base message, INCLUDING itself

# If script is cancelled prematurely, you can start where you left off
# You MUST delete the file if you change the number and/or content of the input messages
# changes, because base message similarity calculation will be skipped if it's already in
# here, and none of the additional messages will be added to the similarity family
if os.path.isfile("alpha_similarity_families.txt"):
    with open("alpha_similarity_families.txt", "r") as f:
        for family in f.readlines():
            base_msg, similar_msgs = family.split("\t")
            similar_msgs = set([x.strip() for x in similar_msgs.split(",")])
            deemed_similar.update(similar_msgs)
            similarity_families[base_msg] = set(similar_msgs)

model = hub.load("https://tfhub.dev/google/universal-sentence-encoder/4")
similarity_family_file = open("alpha_similarity_families.txt", "a")

def add_to_similarity_family(base_msg_no, msg_no):
    """Add the given message number to the similarity family of the given base message number"""
    if base_msg_no not in similarity_families:
        similarity_families[base_msg_no] = set()
    similarity_families[base_msg_no].add(msg_no)

def get_embedding_with_caching(message_no, message_content):
    """Get the embedding for the given message and save it to scratch/cache,
    or if it has already been calculated, return the cached embedding"""
    if os.path.isfile(f"{SCRATCH_DIR}/embedding.{message_no}.pkl"):
        with open(f"{SCRATCH_DIR}/embedding.{message_no}.pkl", "rb") as picklefile:
            return pickle.load(picklefile)
    else:
        embedding = model([message_content])
        with open(f"{SCRATCH_DIR}/embedding.{message_no}.pkl", "wb") as picklefile:
            pickle.dump(embedding, picklefile)
        return embedding

# First pass: compute any exact matches and prevent them from being computed again (except for base messages)
for message in MESSAGES:
    if message[0] in deemed_similar: continue
    print(f"(exact pass) Base message {message[0]}: {message[10]}")
    for other_message in MESSAGES:
        if (message[0] == other_message[0]) or (message[0] in deemed_similar): continue
        if message[10] == other_message[10]:
            add_to_similarity_family(message[0], other_message[0])
            deemed_similar.add(other_message[0]) # don't add message[0] because we still want to compute cosine similarity with it
            print(f"Exact message {other_message[0]}: {other_message[10]}")

# Second pass: compute cosine similarity with all other messages
for message in MESSAGES:
    if message[0] in deemed_similar: continue

    print(f"Base message {message[0]}: {message[10]}")
    embedding = get_embedding_with_caching(message[0], message[10])

    for other_message in MESSAGES:
        if (message[0] == other_message[0]) or (other_message[0] in deemed_similar): continue

        other_embedding = get_embedding_with_caching(other_message[0], other_message[10])
        if cosine_similarity(embedding, other_embedding)[0][0] > 0.8:
            print(f"Similar message {other_message[0]}: {other_message[10]}")

            deemed_similar.add(message[0])
            deemed_similar.add(other_message[0])
            add_to_similarity_family(message[0], other_message[0])
            add_to_similarity_family(message[0], message[0])
    if message[0] in similarity_families:
        similarity_family_file.write(f"{message[0]}\t{','.join(similarity_families[message[0]])}\n")
        similarity_family_file.flush() # ensure the file is written to disk immediately
        os.fsync(similarity_family_file.fileno())

similarity_family_file.close()